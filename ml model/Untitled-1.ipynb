{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820b38d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7603 - loss: 0.6986 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 2/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0051 - val_accuracy: 0.9998 - val_loss: 0.0037\n",
      "Epoch 3/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 4/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 7.1159e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.1391e-04 - val_accuracy: 1.0000 - val_loss: 5.4281e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 9.5456e-04 - val_accuracy: 1.0000 - val_loss: 6.5069e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.9981e-04 - val_accuracy: 1.0000 - val_loss: 2.3975e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 9.5667e-04 - val_accuracy: 1.0000 - val_loss: 2.0786e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.1432e-04 - val_accuracy: 0.9998 - val_loss: 0.0013\n",
      "Epoch 10/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 1.9535e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.4628e-05 - val_accuracy: 1.0000 - val_loss: 1.4375e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.6096e-05 - val_accuracy: 1.0000 - val_loss: 8.7989e-05\n",
      "Epoch 13/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.6826e-05 - val_accuracy: 1.0000 - val_loss: 9.2868e-05\n",
      "Epoch 14/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.7407e-05 - val_accuracy: 1.0000 - val_loss: 4.4684e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.0027e-04 - val_accuracy: 1.0000 - val_loss: 2.0495e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.9125e-05 - val_accuracy: 1.0000 - val_loss: 1.6967e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 1.8433e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.8511e-05 - val_accuracy: 1.0000 - val_loss: 1.3477e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.3905e-05 - val_accuracy: 1.0000 - val_loss: 1.0853e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.3170e-05 - val_accuracy: 1.0000 - val_loss: 9.6435e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5854e-04 - val_accuracy: 0.9920 - val_loss: 0.0200\n",
      "Epoch 23/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 1.0215e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.1570e-05 - val_accuracy: 1.0000 - val_loss: 8.6614e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.9953e-05 - val_accuracy: 1.0000 - val_loss: 7.0625e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.9295e-05 - val_accuracy: 1.0000 - val_loss: 5.8397e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.4699e-05 - val_accuracy: 1.0000 - val_loss: 7.0792e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.6404e-05 - val_accuracy: 1.0000 - val_loss: 7.7415e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 1.7066e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.4842e-05 - val_accuracy: 1.0000 - val_loss: 8.9428e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.3973e-05 - val_accuracy: 1.0000 - val_loss: 8.6155e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.6475e-05 - val_accuracy: 1.0000 - val_loss: 6.3275e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.9802e-05 - val_accuracy: 1.0000 - val_loss: 5.7593e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.8280e-05 - val_accuracy: 1.0000 - val_loss: 4.4214e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3494e-05 - val_accuracy: 1.0000 - val_loss: 3.2767e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.3339e-05 - val_accuracy: 1.0000 - val_loss: 3.2861e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3396e-05 - val_accuracy: 1.0000 - val_loss: 2.0205e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.4418e-06 - val_accuracy: 0.9998 - val_loss: 7.2549e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 8.1622e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.5333e-05 - val_accuracy: 1.0000 - val_loss: 5.8486e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7005e-05 - val_accuracy: 1.0000 - val_loss: 4.0136e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 629ms/step - accuracy: 1.0000 - loss: 1.8435e-05 - val_accuracy: 1.0000 - val_loss: 3.1387e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.4843e-05 - val_accuracy: 1.0000 - val_loss: 2.5736e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0452e-05 - val_accuracy: 1.0000 - val_loss: 2.2057e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 7.6269e-06 - val_accuracy: 1.0000 - val_loss: 1.9966e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.3245e-06 - val_accuracy: 1.0000 - val_loss: 1.2837e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0961e-06 - val_accuracy: 1.0000 - val_loss: 1.6316e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7834e-06 - val_accuracy: 1.0000 - val_loss: 1.7728e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 4.2146e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1834e-05 - val_accuracy: 1.0000 - val_loss: 3.2323e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4106e-05 - val_accuracy: 1.0000 - val_loss: 2.1785e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.3169e-06 - val_accuracy: 1.0000 - val_loss: 1.6240e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6280e-06 - val_accuracy: 1.0000 - val_loss: 1.3362e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3528e-06 - val_accuracy: 1.0000 - val_loss: 1.8228e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4854e-06 - val_accuracy: 1.0000 - val_loss: 8.5665e-06\n",
      "Epoch 56/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3647e-06 - val_accuracy: 1.0000 - val_loss: 8.5131e-06\n",
      "Epoch 57/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.3415e-06 - val_accuracy: 1.0000 - val_loss: 7.6211e-06\n",
      "Epoch 58/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4696e-06 - val_accuracy: 1.0000 - val_loss: 7.6229e-06\n",
      "Epoch 59/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.7331e-06 - val_accuracy: 1.0000 - val_loss: 4.8707e-06\n",
      "Epoch 60/60\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.0156e-06 - val_accuracy: 1.0000 - val_loss: 2.6148e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and normalization data saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import random\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Generate synthetic data with 5 classes\n",
    "def generate_data(samples=15000):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for _ in range(samples):\n",
    "        r = random.random()\n",
    "        if r < 0.2:\n",
    "            # Normal: 20–28°C, 40–60%\n",
    "            temp = random.uniform(20, 28)\n",
    "            hum = random.uniform(40, 60)\n",
    "            label = 0\n",
    "        elif r < 0.4:\n",
    "            # Hot and Humid: >28°C, >60%\n",
    "            temp = random.uniform(29, 40)\n",
    "            hum = random.uniform(61, 90)\n",
    "            label = 1\n",
    "        elif r < 0.6:\n",
    "            # Cold and Dry: <18°C, <40%\n",
    "            temp = random.uniform(5, 17)\n",
    "            hum = random.uniform(10, 39)\n",
    "            label = 2\n",
    "        elif r < 0.8:\n",
    "            # Hot and Dry: >28°C, <40%\n",
    "            temp = random.uniform(29, 40)\n",
    "            hum = random.uniform(10, 39)\n",
    "            label = 3\n",
    "        else:\n",
    "            # Cold and Humid: <18°C, >60%\n",
    "            temp = random.uniform(5, 17)\n",
    "            hum = random.uniform(61, 90)\n",
    "            label = 4\n",
    "\n",
    "        X.append([temp, hum])\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Generate data\n",
    "X, y = generate_data(20000)\n",
    "\n",
    "# Normalize features\n",
    "X_min = X.min(axis=0)\n",
    "X_max = X.max(axis=0)\n",
    "X_norm = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "# Build a deeper neural network\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(2,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_norm, y, epochs=60, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save model and normalization data\n",
    "model.save(\"dht_classifier.h5\")\n",
    "np.savez(\"normalization.npz\", min=X_min, max=X_max)\n",
    "\n",
    "print(\"✅ Model and normalization data saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
